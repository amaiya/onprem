{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# | export\n",
    "import os.path\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "\n",
    "def download(url, filename, verify=False):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        response = requests.get(url, stream=True, verify=verify)\n",
    "        total = response.headers.get(\"content-length\")\n",
    "\n",
    "        if total is None:\n",
    "            f.write(response.content)\n",
    "        else:\n",
    "            downloaded = 0\n",
    "            total = int(total)\n",
    "            # print(total)\n",
    "            for data in response.iter_content(\n",
    "                chunk_size=max(int(total / 1000), 1024 * 1024)\n",
    "            ):\n",
    "                downloaded += len(data)\n",
    "                f.write(data)\n",
    "                done = int(50 * downloaded / total)\n",
    "                sys.stdout.write(\"\\r[{}{}]\".format(\"â–ˆ\" * done, \".\" * (50 - done)))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "\n",
    "def get_datadir():\n",
    "    home = os.path.expanduser(\"~\")\n",
    "    datadir = os.path.join(home, \"onprem_data\")\n",
    "    if not os.path.isdir(datadir):\n",
    "        os.mkdir(datadir)\n",
    "    return datadir\n",
    "\n",
    "\n",
    "def split_list(input_list, chunk_size):\n",
    "    for i in range(0, len(input_list), chunk_size):\n",
    "        yield input_list[i : i + chunk_size]\n",
    "\n",
    "\n",
    "from syntok import segmenter\n",
    "import textwrap\n",
    "def segment(text:str, unit:str='paragraph', maxchars:int=2048):\n",
    "    \"\"\"\n",
    "    Segments text into a list of paragraphs or sentences depending on value of `unit` \n",
    "    (one of `{'paragraph', 'sentence'}`. The `maxchars` parameter is the maximum size\n",
    "    of any unit of text.\n",
    "    \"\"\"\n",
    "    units = []\n",
    "    for paragraph in segmenter.analyze(text):\n",
    "        sentences = []\n",
    "        for sentence in paragraph:\n",
    "            text = \"\"\n",
    "            for token in sentence:\n",
    "                text += f'{token.spacing}{token.value}'\n",
    "            sentences.append(text)\n",
    "        if unit == 'sentence':\n",
    "            units.extend(sentences)\n",
    "        else:\n",
    "            units.append(\" \".join(sentences))\n",
    "    chunks = []\n",
    "    for s in units:\n",
    "        parts = textwrap.wrap(s, maxchars, break_long_words=False)\n",
    "        chunks.extend(parts)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
