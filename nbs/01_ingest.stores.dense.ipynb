{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ingest.stores.dense\n",
    "\n",
    "> Data store for dense vector represenations of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp ingest.stores.dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from onprem.ingest.base import VectorStore\n",
    "\n",
    "\n",
    "class DenseStore(VectorStore):\n",
    "    def __init__(self, **kwargs):\n",
    "        if type(self) is DenseStore:\n",
    "            raise TypeError(\"Use the DenseStore.create() method instead of instantiating DenseStore directly.\")\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, persist_directory=None, kind=None, **kwargs) -> 'DenseStore':\n",
    "        \"\"\"\n",
    "        Factory method to construct a `DenseStore` instance.       \n",
    "        Extra kwargs passed to object instantiation.\n",
    "        \n",
    "        Args:\n",
    "            persist_directory: where the vector database is stored\n",
    "            kind: one of {chroma}\n",
    "\n",
    "        Returns:\n",
    "            DenseStore instance\n",
    "        \"\"\"\n",
    "        \n",
    "        kind = 'chroma' if not kind else kind\n",
    "        \n",
    "        if kind == 'chroma':\n",
    "            return ChromaStore(persist_directory=persist_directory, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown DenseStore type: {kind}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from typing import List, Optional, Callable, Dict, Sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "from onprem.ingest.helpers import doc_from_dict\n",
    "from onprem.utils import get_datadir, DEFAULT_DB\n",
    "from onprem.ingest.base import batchify_chunks, process_folder, does_vectorstore_exist\n",
    "from onprem.ingest.base import CHROMA_MAX\n",
    "try:\n",
    "    from langchain_chroma import Chroma\n",
    "    import chromadb\n",
    "    from chromadb.config import Settings\n",
    "    CHROMA_INSTALLED = True\n",
    "except ImportError:\n",
    "    CHROMA_INSTALLED = False\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"0\"\n",
    "COLLECTION_NAME = \"onprem_chroma\"\n",
    "\n",
    "\n",
    "class ChromaStore(DenseStore):\n",
    "    def __init__(\n",
    "        self,\n",
    "        persist_directory: Optional[str] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Ingests all documents in `source_folder` (previously-ingested documents are ignored)\n",
    "\n",
    "        **Args**:\n",
    "\n",
    "          - *persist_directory*: Path to vector database (created if it doesn't exist).\n",
    "                                 Default is `onprem_data/vectordb` in user's home directory.\n",
    "          - *embedding_model*: name of sentence-transformers model\n",
    "          - *embedding_model_kwargs*: arguments to embedding model (e.g., `{device':'cpu'}`). If None, GPU used if available.\n",
    "          - *embedding_encode_kwargs*: arguments to encode method of\n",
    "                                       embedding model (e.g., `{'normalize_embeddings': False}`).\n",
    "\n",
    "\n",
    "        **Returns**: `None`\n",
    "        \"\"\"\n",
    "        if not CHROMA_INSTALLED:\n",
    "            raise ImportError('Please install chroma packages: pip install onprem[chroma]')\n",
    "\n",
    "        from langchain_chroma import Chroma\n",
    "        import chromadb\n",
    "        from chromadb.config import Settings\n",
    "\n",
    "        self.persist_directory = persist_directory or os.path.join(\n",
    "            get_datadir(), DEFAULT_DB\n",
    "        )\n",
    "        self.init_embedding_model(**kwargs) # stored in self.embeddings\n",
    "\n",
    "        self.chroma_settings = Settings(\n",
    "            persist_directory=self.persist_directory, anonymized_telemetry=False\n",
    "        )\n",
    "        self.chroma_client = chromadb.PersistentClient(\n",
    "            settings=self.chroma_settings, path=self.persist_directory\n",
    "        )\n",
    "        return\n",
    "\n",
    "\n",
    "    def _convert_to_dict(self, raw_results):\n",
    "        \"\"\"\n",
    "        Convert raw results to dictionary\n",
    "        \"\"\"\n",
    "        ids = raw_results['ids']\n",
    "        texts = raw_results['documents']\n",
    "        metadatas = raw_results['metadatas']\n",
    "        results = []\n",
    "        for i, m in enumerate(metadatas):\n",
    "            m['page_content'] = texts[i]\n",
    "            m['id'] = ids[i]\n",
    "            results.append(m)\n",
    "        return results\n",
    "\n",
    "    def get_db(self):\n",
    "        \"\"\"\n",
    "        Returns an instance to the `langchain_chroma.Chroma` instance\n",
    "        \"\"\"\n",
    "        # Create ChromaDB settings\n",
    "        db = Chroma(\n",
    "            persist_directory=self.persist_directory,\n",
    "            embedding_function=self.embeddings,\n",
    "            client_settings=self.chroma_settings,\n",
    "            client=self.chroma_client,\n",
    "            collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "            collection_name=COLLECTION_NAME,\n",
    "        )\n",
    "        return db if does_vectorstore_exist(db) else None\n",
    "    \n",
    "    #------------------------------\n",
    "    # overrides of abstract methods\n",
    "    # -----------------------------\n",
    "    \n",
    "\n",
    "    def exists(self):\n",
    "        return self.get_db() is not None\n",
    "\n",
    "\n",
    "    def add_documents(self, documents, batch_size:int=CHROMA_MAX):\n",
    "        \"\"\"\n",
    "        Stores instances of `langchain_core.documents.base.Document` in vectordb\n",
    "        \"\"\"\n",
    "        if not documents:\n",
    "            return\n",
    "        db = self.get_db()\n",
    "        if db:\n",
    "            print(\"Creating embeddings. May take some minutes...\")\n",
    "            chunk_batches, total_chunks = batchify_chunks(documents, batch_size=batch_size)\n",
    "            for lst in tqdm(chunk_batches, total=total_chunks):\n",
    "                db.add_documents(lst)\n",
    "        else:\n",
    "            chunk_batches, total_chunks = batchify_chunks(documents, batch_size)\n",
    "            print(\"Creating embeddings. May take some minutes...\")\n",
    "            db = None\n",
    "\n",
    "            for lst in tqdm(chunk_batches, total=total_chunks):\n",
    "                if not db:\n",
    "                    db = Chroma.from_documents(\n",
    "                        lst,\n",
    "                        self.embeddings,\n",
    "                        persist_directory=self.persist_directory,\n",
    "                        client_settings=self.chroma_settings,\n",
    "                        client=self.chroma_client,\n",
    "                        collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "                        collection_name=COLLECTION_NAME,\n",
    "                    )\n",
    "                else:\n",
    "                    db.add_documents(lst)\n",
    "        return\n",
    "\n",
    "\n",
    "    def remove_document(self, id_to_delete):\n",
    "        \"\"\"\n",
    "        Remove a single document with ID, `id_to_delete`.\n",
    "        \"\"\"\n",
    "        if not self.exists(): return\n",
    "        id_to_delete = [id_to_delete] if not isinstance(id_to_delete, list) else id_to_delete\n",
    "        self.get_db().delete(ids=id_to_delete)\n",
    "        return\n",
    "\n",
    "    def remove_source(self, source:str):\n",
    "        \"\"\"\n",
    "        Deletes all documents in a Chroma collection whose `source` metadata field starts with the given prefix.\n",
    "        The `source` argument can either be a full path to a document or a prefix (e.g., parent folder).\n",
    "\n",
    "        **Args:**\n",
    "        - *source*: The source value or prefix\n",
    "\n",
    "        **Returns:**\n",
    "        - The number of documents deleted\n",
    "        \"\"\"\n",
    "        db = self.get_db()\n",
    "\n",
    "        # Only request metadata; ids are returned automatically\n",
    "        results = db.get(include=[\"metadatas\"])\n",
    "\n",
    "        to_delete = []\n",
    "        for doc_id, metadata in zip(results[\"ids\"], results[\"metadatas\"]):\n",
    "            if metadata and \"source\" in metadata:\n",
    "                if metadata[\"source\"].startswith(source):\n",
    "                    to_delete.append(doc_id)\n",
    "\n",
    "        if to_delete:\n",
    "            db.delete(ids=to_delete)\n",
    "            return len(to_delete)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def update_documents(self,\n",
    "                         doc_dicts:dict, # dictionary with keys 'page_content', 'source', 'id', etc.\n",
    "                         **kwargs):\n",
    "\n",
    "        \"\"\"\n",
    "        Update a set of documents (doc in index with same ID will be over-written)\n",
    "        \"\"\"\n",
    "        self.check()\n",
    "        db = self.get_db()\n",
    "        docs = [doc_from_dict(d) for d in doc_dicts]\n",
    "        ids = [d['id'] for d in doc_dicts]\n",
    "        return db.update_documents(ids, docs)\n",
    "\n",
    "\n",
    "   \n",
    "    def get_all_docs(self):\n",
    "        \"\"\"\n",
    "        Returns all docs\n",
    "        \"\"\"\n",
    "        if not self.exists(): return []\n",
    "\n",
    "        raw_results =  self.get_db().get()\n",
    "        return self._convert_to_dict(raw_results)\n",
    "\n",
    "\n",
    "    def get_doc(self, id):\n",
    "        \"\"\"\n",
    "        Retrieve a record by ID\n",
    "        \"\"\"\n",
    "        if not self.exists(): return None\n",
    "        raw_results = self.get_db().get(ids=[id])\n",
    "        return self._convert_to_dict(raw_results)[0] if len(raw_results['ids']) > 0 else None\n",
    "\n",
    "    \n",
    "    def get_size(self):\n",
    "        \"\"\"\n",
    "        Get total number of records\n",
    "        \"\"\"\n",
    "        if not self.exists(): return 0\n",
    "        return len(self.get_db().get()['documents'])\n",
    "\n",
    "    \n",
    "    def erase(self, confirm=True):\n",
    "        \"\"\"\n",
    "        Resets collection and removes and stored documents\n",
    "        \"\"\"\n",
    "        if not self.exists(): return True\n",
    "        shall = True\n",
    "        if confirm:\n",
    "            msg = (\n",
    "                f\"You are about to remove all documents from the vector database.\"\n",
    "                + f\"(Original documents on file system will remain.) Are you sure?\"\n",
    "            )\n",
    "            shall = input(\"%s (Y/n) \" % msg) == \"Y\"\n",
    "        if shall:\n",
    "            self.get_db().reset_collection()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def query(self,\n",
    "              query:str, # query string\n",
    "              k:int = 4, # max number of results to return\n",
    "              filters:Optional[Dict[str, str]] = None, # filter sources by metadata values using Chroma metadata syntax (e.g., {'table':True})\n",
    "              where_document:Optional[Dict[str, str]] = None, # filter sources by document content in Chroma syntax (e.g., {\"$contains\": \"Canada\"})\n",
    "              **kwargs):\n",
    "        \"\"\"\n",
    "        Perform a semantic search of the vector DB\n",
    "        \"\"\"\n",
    "        if not self.exists(): return []\n",
    "        db = self.get_db()\n",
    "        results = db.similarity_search_with_score(query, \n",
    "                                                  filter=filters,\n",
    "                                                  where_document=where_document,\n",
    "                                                  k = k, **kwargs)\n",
    "        if not results: return []\n",
    "        docs, scores = zip(*results)\n",
    "        for doc, score in zip(docs, scores):\n",
    "            simscore = 1 - score\n",
    "            doc.metadata[\"score\"] = 1-score\n",
    "        return docs      \n",
    "\n",
    "    def semantic_search(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Semantic search is equivalent to queries in this class\n",
    "        \"\"\"\n",
    "        return self.query(*args, **kwargs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L136){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.exists\n",
       "\n",
       ">      ChromaStore.exists ()\n",
       "\n",
       "*Returns True if vector store has been initialized and contains documents.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L136){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.exists\n",
       "\n",
       ">      ChromaStore.exists ()\n",
       "\n",
       "*Returns True if vector store has been initialized and contains documents.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L140){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.add_documents\n",
       "\n",
       ">      ChromaStore.add_documents (documents, batch_size:int=41000)\n",
       "\n",
       "*Stores instances of `langchain_core.documents.base.Document` in vectordb*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L140){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.add_documents\n",
       "\n",
       ">      ChromaStore.add_documents (documents, batch_size:int=41000)\n",
       "\n",
       "*Stores instances of `langchain_core.documents.base.Document` in vectordb*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.add_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L173){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.remove_document\n",
       "\n",
       ">      ChromaStore.remove_document (id_to_delete)\n",
       "\n",
       "*Remove a single document with ID, `id_to_delete`.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L173){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.remove_document\n",
       "\n",
       ">      ChromaStore.remove_document (id_to_delete)\n",
       "\n",
       "*Remove a single document with ID, `id_to_delete`.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.remove_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L182){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.remove_source\n",
       "\n",
       ">      ChromaStore.remove_source (source:str)\n",
       "\n",
       "*Deletes all documents in a Chroma collection whose `source` metadata field starts with the given prefix.\n",
       "The `source` argument can either be a full path to a document or a prefix (e.g., parent folder).\n",
       "\n",
       "**Args:**\n",
       "- *source*: The source value or prefix\n",
       "\n",
       "**Returns:**\n",
       "- The number of documents deleted*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L182){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.remove_source\n",
       "\n",
       ">      ChromaStore.remove_source (source:str)\n",
       "\n",
       "*Deletes all documents in a Chroma collection whose `source` metadata field starts with the given prefix.\n",
       "The `source` argument can either be a full path to a document or a prefix (e.g., parent folder).\n",
       "\n",
       "**Args:**\n",
       "- *source*: The source value or prefix\n",
       "\n",
       "**Returns:**\n",
       "- The number of documents deleted*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.remove_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L210){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.update_documents\n",
       "\n",
       ">      ChromaStore.update_documents (doc_dicts:dict, **kwargs)\n",
       "\n",
       "*Update a set of documents (doc in index with same ID will be over-written)*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| doc_dicts | dict | dictionary with keys 'page_content', 'source', 'id', etc. |\n",
       "| kwargs | VAR_KEYWORD |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L210){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.update_documents\n",
       "\n",
       ">      ChromaStore.update_documents (doc_dicts:dict, **kwargs)\n",
       "\n",
       "*Update a set of documents (doc in index with same ID will be over-written)*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| doc_dicts | dict | dictionary with keys 'page_content', 'source', 'id', etc. |\n",
       "| kwargs | VAR_KEYWORD |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.update_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L225){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.get_all_docs\n",
       "\n",
       ">      ChromaStore.get_all_docs ()\n",
       "\n",
       "*Returns all docs*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L225){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.get_all_docs\n",
       "\n",
       ">      ChromaStore.get_all_docs ()\n",
       "\n",
       "*Returns all docs*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.get_all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L235){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.get_doc\n",
       "\n",
       ">      ChromaStore.get_doc (id)\n",
       "\n",
       "*Retrieve a record by ID*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L235){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.get_doc\n",
       "\n",
       ">      ChromaStore.get_doc (id)\n",
       "\n",
       "*Retrieve a record by ID*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.get_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L244){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.get_size\n",
       "\n",
       ">      ChromaStore.get_size ()\n",
       "\n",
       "*Get total number of records*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L244){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.get_size\n",
       "\n",
       ">      ChromaStore.get_size ()\n",
       "\n",
       "*Get total number of records*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.get_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L252){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.erase\n",
       "\n",
       ">      ChromaStore.erase (confirm=True)\n",
       "\n",
       "*Resets collection and removes and stored documents*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L252){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.erase\n",
       "\n",
       ">      ChromaStore.erase (confirm=True)\n",
       "\n",
       "*Resets collection and removes and stored documents*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.erase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L270){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.query\n",
       "\n",
       ">      ChromaStore.query (query:str, k:int=4,\n",
       ">                         filters:Optional[Dict[str,str]]=None,\n",
       ">                         where_document:Optional[Dict[str,str]]=None, **kwargs)\n",
       "\n",
       "*Perform a semantic search of the vector DB*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| query | str |  | query string |\n",
       "| k | int | 4 | max number of results to return |\n",
       "| filters | Optional | None | filter sources by metadata values using Chroma metadata syntax (e.g., {'table':True}) |\n",
       "| where_document | Optional | None | filter sources by document content in Chroma syntax (e.g., {\"$contains\": \"Canada\"}) |\n",
       "| kwargs | VAR_KEYWORD |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L270){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.query\n",
       "\n",
       ">      ChromaStore.query (query:str, k:int=4,\n",
       ">                         filters:Optional[Dict[str,str]]=None,\n",
       ">                         where_document:Optional[Dict[str,str]]=None, **kwargs)\n",
       "\n",
       "*Perform a semantic search of the vector DB*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| query | str |  | query string |\n",
       "| k | int | 4 | max number of results to return |\n",
       "| filters | Optional | None | filter sources by metadata values using Chroma metadata syntax (e.g., {'table':True}) |\n",
       "| where_document | Optional | None | filter sources by document content in Chroma syntax (e.g., {\"$contains\": \"Canada\"}) |\n",
       "| kwargs | VAR_KEYWORD |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L292){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.semantic_search\n",
       "\n",
       ">      ChromaStore.semantic_search (*args, **kwargs)\n",
       "\n",
       "*Semantic search is equivalent to queries in this class*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/stores/dense.py#L292){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ChromaStore.semantic_search\n",
       "\n",
       ">      ChromaStore.semantic_search (*args, **kwargs)\n",
       "\n",
       "*Semantic search is equivalent to queries in this class*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.semantic_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/base.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### VectorStore.ingest\n",
       "\n",
       ">      VectorStore.ingest (source_directory:str, chunk_size:int=500,\n",
       ">                          chunk_overlap:int=50,\n",
       ">                          ignore_fn:Optional[Callable]=None,\n",
       ">                          batch_size:int=41000, **kwargs)\n",
       "\n",
       "*Ingests all documents in `source_directory` (previously-ingested documents are\n",
       "ignored). When retrieved, the\n",
       "[Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html)\n",
       "objects will each have a `metadata` dict with the absolute path to the file\n",
       "in `metadata[\"source\"]`.\n",
       "Extra kwargs fed to `ingest.load_single_document`.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| source_directory | str |  | path to folder containing document store |\n",
       "| chunk_size | int | 500 | text is split to this many characters by [langchain.text_splitter.RecursiveCharacterTextSplitter](https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html) |\n",
       "| chunk_overlap | int | 50 | character overlap between chunks in `langchain.text_splitter.RecursiveCharacterTextSplitter` |\n",
       "| ignore_fn | Optional | None | Optional function that accepts the file path (including file name) as input and returns `True` if file path should not be ingested. |\n",
       "| batch_size | int | 41000 | batch size used when processing documents |\n",
       "| kwargs | VAR_KEYWORD |  |  |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/amaiya/onprem/blob/master/onprem/ingest/base.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### VectorStore.ingest\n",
       "\n",
       ">      VectorStore.ingest (source_directory:str, chunk_size:int=500,\n",
       ">                          chunk_overlap:int=50,\n",
       ">                          ignore_fn:Optional[Callable]=None,\n",
       ">                          batch_size:int=41000, **kwargs)\n",
       "\n",
       "*Ingests all documents in `source_directory` (previously-ingested documents are\n",
       "ignored). When retrieved, the\n",
       "[Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html)\n",
       "objects will each have a `metadata` dict with the absolute path to the file\n",
       "in `metadata[\"source\"]`.\n",
       "Extra kwargs fed to `ingest.load_single_document`.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| source_directory | str |  | path to folder containing document store |\n",
       "| chunk_size | int | 500 | text is split to this many characters by [langchain.text_splitter.RecursiveCharacterTextSplitter](https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html) |\n",
       "| chunk_overlap | int | 50 | character overlap between chunks in `langchain.text_splitter.RecursiveCharacterTextSplitter` |\n",
       "| ignore_fn | Optional | None | Optional function that accepts the file path (including file name) as input and returns `True` if file path should not be ingested. |\n",
       "| batch_size | int | 41000 | batch size used when processing documents |\n",
       "| kwargs | VAR_KEYWORD |  |  |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ChromaStore.ingest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "tempfolder = temp_dir.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vectorstore at /tmp/tmpmftvr854\n",
      "Loading documents from tests/sample_data/ktrain_paper/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading new documents: 100%|██████████████████████| 1/1 [00:00<00:00,  7.85it/s]\n",
      "Processing and chunking 6 new documents: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 985.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 41 chunks of text (max. 500 chars each for text; max. 2000 chars for tables)\n",
      "Creating embeddings. May take some minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion complete! You can now query your documents using the LLM.ask or LLM.chat methods\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "store = DenseStore.create(tempfolder)\n",
    "store.ingest(\"tests/sample_data/ktrain_paper/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.ChromaStore"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "type(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | notest\n",
    "store.get_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "a_document = store.get_all_docs()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "store.remove_document(a_document['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | notest\n",
    "store.get_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
