{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llm helpers\n",
    "\n",
    "> Helper utilities for using LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp llm.helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from onprem.utils import SafeFormatter\n",
    "import json\n",
    "import yaml\n",
    "from typing import List, Any, Union, Callable\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.documents import Document\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def truncate_prompt(model_or_pipeline, prompt, max_gen_tokens=512, truncate_from=\"start\", prompt_template=None):\n",
    "    \"\"\"\n",
    "    Truncate only the user prompt (not the full formatted prompt) to ensure\n",
    "    the total prompt (template + user prompt) fits in model's context.\n",
    "\n",
    "    Args:\n",
    "        model_or_pipeline: \n",
    "            - llama_cpp.Llama\n",
    "            - HuggingFace pipeline (with .tokenizer)\n",
    "            - HuggingFace tokenizer\n",
    "        prompt (str): The user-supplied prompt (to be truncated if needed).\n",
    "        max_gen_tokens (int): Tokens to reserve for generation.\n",
    "        truncate_from (str): 'start' or 'end'.\n",
    "        prompt_template (str, optional): Template with {prompt}. Used to reserve space for non-user text.\n",
    "\n",
    "    Returns:\n",
    "        str: Truncated user prompt only (template not applied).\n",
    "    \"\"\"\n",
    "    # Resolve tokenizer\n",
    "    if hasattr(model_or_pipeline, \"tokenize\") and hasattr(model_or_pipeline, \"detokenize\"):\n",
    "        # llama_cpp\n",
    "        tokenizer = model_or_pipeline\n",
    "        tokenize = lambda text: tokenizer.tokenize(text.encode(\"utf-8\"))\n",
    "        detokenize = lambda tokens: tokenizer.detokenize(tokens).decode(\"utf-8\")\n",
    "        n_ctx = tokenizer.n_ctx()\n",
    "    elif hasattr(model_or_pipeline, \"tokenizer\"):\n",
    "        # HuggingFace pipeline\n",
    "        tokenizer = model_or_pipeline.tokenizer\n",
    "        tokenize = lambda text: tokenizer.encode(text, add_special_tokens=False)\n",
    "        detokenize = lambda tokens: tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "        n_ctx = getattr(tokenizer, \"model_max_length\", 4096)\n",
    "    elif hasattr(model_or_pipeline, \"encode\") and hasattr(model_or_pipeline, \"decode\"):\n",
    "        # HuggingFace tokenizer directly\n",
    "        tokenizer = model_or_pipeline\n",
    "        tokenize = lambda text: tokenizer.encode(text, add_special_tokens=False)\n",
    "        detokenize = lambda tokens: tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "        n_ctx = getattr(tokenizer, \"model_max_length\", 4096)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model_or_pipeline type.\")\n",
    "\n",
    "    # If prompt_template is provided, reserve space for it\n",
    "    if prompt_template:\n",
    "        empty_filled_template = prompt_template.format(prompt=\"\")\n",
    "        template_tokens = tokenize(empty_filled_template)\n",
    "    else:\n",
    "        template_tokens = []\n",
    "\n",
    "    prompt_tokens = tokenize(prompt)\n",
    "    max_prompt_tokens = n_ctx - max_gen_tokens - len(template_tokens)\n",
    "\n",
    "    if max_prompt_tokens < 0:\n",
    "        raise ValueError(\"Template and generation tokens exceed model context window.\")\n",
    "\n",
    "    if len(prompt_tokens) > max_prompt_tokens:\n",
    "        if truncate_from == \"start\":\n",
    "            prompt_tokens = prompt_tokens[-max_prompt_tokens:]\n",
    "        elif truncate_from == \"end\":\n",
    "            prompt_tokens = prompt_tokens[:max_prompt_tokens]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid truncate_from='{truncate_from}'. Use 'start' or 'end'.\")\n",
    "\n",
    "    return detokenize(prompt_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def _marshal_llm_to_json(output: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract a substring containing valid JSON or array from a string.\n",
    "\n",
    "    **Args:**\n",
    "    \n",
    "        - output: A string that may contain a valid JSON object or array surrounded by extraneous characters or information.\n",
    "\n",
    "    **Returns:**\n",
    "        \n",
    "        - A string containing a valid JSON object or array.\n",
    "    \"\"\"\n",
    "    output = output.strip()\n",
    "\n",
    "    left_square = output.find(\"[\")\n",
    "    left_brace = output.find(\"{\")\n",
    "\n",
    "    if left_square < left_brace and left_square != -1:\n",
    "        left = left_square\n",
    "        right = output.rfind(\"]\")\n",
    "    else:\n",
    "        left = left_brace\n",
    "        right = output.rfind(\"}\")\n",
    "\n",
    "    return output[left : right + 1]\n",
    "\n",
    "\n",
    "def extract_json(text:str) -> str:\n",
    "    \"\"\"\n",
    "    Atttempts to extract json from markdown string.\n",
    "    If no json exists, then return empty string.\n",
    "    \"\"\"\n",
    "    if \"```json\" in text:\n",
    "        text = text.split(\"```json\")[1].strip().strip(\"```\").strip()\n",
    "    \n",
    "    return _marshal_llm_to_json(text)\n",
    "\n",
    "\n",
    "def parse_json_markdown(text: str) -> Any:\n",
    "    \"\"\"\n",
    "    Parse json embedded in markdown into dictionary\n",
    "    \"\"\"\n",
    "    json_string = extract_json(text)\n",
    "\n",
    "    try:\n",
    "        json_obj = json.loads(json_string)\n",
    "    except json.JSONDecodeError as e_json:\n",
    "        try:\n",
    "            # NOTE: parsing again with pyyaml\n",
    "            #       pyyaml is less strict, and allows for trailing commas\n",
    "            #       right now we rely on this since guidance program generates\n",
    "            #       trailing commas\n",
    "            json_obj = yaml.safe_load(json_string)\n",
    "        except yaml.YAMLError as e_yaml:\n",
    "            raise OutputParserException(\n",
    "                f\"Got invalid JSON object. Error: {e_json} {e_yaml}. \"\n",
    "                f\"Got JSON string: {json_string}\"\n",
    "            )\n",
    "        except NameError as exc:\n",
    "            raise ImportError(\"Please pip install PyYAML.\") from exc\n",
    "\n",
    "    return json_obj\n",
    "\n",
    "def parse_code_markdown(text: str, only_last: bool) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parsing embedded code out of markdown string\n",
    "    \"\"\"\n",
    "    # Regular expression pattern to match code within triple-backticks\n",
    "    pattern = r\"```(.*?)```\"\n",
    "\n",
    "    # Find all matches of the pattern in the text\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    # Return the last matched group if requested\n",
    "    code = matches[-1] if matches and only_last else matches\n",
    "\n",
    "    # If empty we optimistically assume the output is the code\n",
    "    if not code:\n",
    "        # we want to handle cases where the code may start or end with triple\n",
    "        # backticks\n",
    "        # we also want to handle cases where the code is surrounded by regular\n",
    "        # quotes\n",
    "        # we can't just remove all backticks due to JS template strings\n",
    "\n",
    "        candidate = text.strip()\n",
    "\n",
    "        if candidate.startswith('\"') and candidate.endswith('\"'):\n",
    "            candidate = candidate[1:-1]\n",
    "\n",
    "        if candidate.startswith(\"'\") and candidate.endswith(\"'\"):\n",
    "            candidate = candidate[1:-1]\n",
    "\n",
    "        if candidate.startswith(\"`\") and candidate.endswith(\"`\"):\n",
    "            candidate = candidate[1:-1]\n",
    "\n",
    "        # For triple backticks we split the handling of the start and end\n",
    "        # partly because there can be cases where only one and not the other\n",
    "        # is present, and partly because we don't need to be so worried\n",
    "        # about it being a string in a programming language\n",
    "        if candidate.startswith(\"```\"):\n",
    "            candidate = re.sub(r\"^```[a-zA-Z]*\", \"\", candidate)\n",
    "\n",
    "        if candidate.endswith(\"```\"):\n",
    "            candidate = candidate[:-3]\n",
    "        code = [candidate.strip()]\n",
    "\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "TITLE_PROMPT = \"\"\"\\\n",
    "Context: {context_str}.\\n\\nGive a title that summarizes what the context describes. \\\n",
    "Title: \"\"\"\n",
    "\n",
    "class Title(BaseModel):\n",
    "    title: str = Field(description=\"title of text\")\n",
    "\n",
    "def extract_title(docs_or_text:Union[List[Document], str], llm, max_words=1024, retries=1, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract or infer the title for the given text\n",
    "\n",
    "    **Args**\n",
    "      - docs_or_text: Either a list of LangChain Document objects or a single text string\n",
    "      - llm: An onprem.LLM instance\n",
    "      - max_words: Maximum words to consider\n",
    "      - retries: Number of tries to correctly extract title\n",
    "    \"\"\"\n",
    "    if not docs_or_text:\n",
    "        raise ValueError('docs_or_text cannot be empty')\n",
    "    if isinstance(docs_or_text, list):\n",
    "        text = \"\"\n",
    "        for doc in docs_or_text:\n",
    "            if not doc.page_content.strip() or len(doc.page_content.strip()) < 32:\n",
    "                continue\n",
    "            text = doc.page_content.strip()\n",
    "            break\n",
    "    else:\n",
    "        text = docs_or_text\n",
    "    text = \" \".join(text.split()[:max_words])\n",
    "    for i in range(retries+1):\n",
    "        obj = llm.pydantic_prompt(TITLE_PROMPT.replace(\"{context_str}\", text), pydantic_model=Title)\n",
    "        if not isinstance(obj, str):\n",
    "            break\n",
    "    return \"\" if isinstance(obj, str) else obj.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "FOLLOWUP_PROMPT = \"\"\"\\\n",
    "Given a question, answer \"yes\" only if the question is complex and follow-up questions are needed or \"no\" if not.\n",
    "Always respond with \"no\" for short questions that are less than 8 words.\n",
    "Answer only with either \"yes\" or \"no\" with no additional text or explanations.\n",
    "\n",
    "# Example 1\n",
    "<User Question>\n",
    "Compare and contrast the revenue growth and EBITDA of Uber and Lyft for year 2021\n",
    "\n",
    "<Output>\n",
    "yes\n",
    "\n",
    "# Example 2\n",
    "<User Question>\n",
    "How is the Coast Guard using artificial intelligence?\n",
    "\n",
    "<Output>\n",
    "No\n",
    "\n",
    "# Example 3\n",
    "<User Question\n",
    "What is AutoGluon?\n",
    "\n",
    "<Output>\n",
    "No\n",
    "\n",
    "# Example 4\n",
    "<User Question>\n",
    "{query_str}\n",
    "\n",
    "<Output>\n",
    "\"\"\"\n",
    "\n",
    "def needs_followup(question:str, llm, parse=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Decide if follow-up questions are needed\n",
    "    \"\"\"\n",
    "    prompt = SafeFormatter({'query_str': question}).format(FOLLOWUP_PROMPT)\n",
    "    output = llm.prompt(prompt)\n",
    "    return \"yes\" in output.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "TITLE_PROMPT = \"\"\"\\\n",
    "Context: {context_str}.\\n\\nGive a title that summarizes what the context describes. \\\n",
    "Title: \"\"\"\n",
    "\n",
    "class Title(BaseModel):\n",
    "    title: str = Field(description=\"title of text\")\n",
    "\n",
    "def extract_title(docs_or_text:Union[List[Document], str], llm, max_words=1024, retries=1, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract or infer the title for the given text\n",
    "\n",
    "    **Args**\n",
    "      - docs_or_text: Either a list of LangChain Document objects or a single text string\n",
    "      - llm: An onprem.LLM instance\n",
    "      - max_words: Maximum words to consider\n",
    "      - retries: Number of tries to correctly extract title\n",
    "    \"\"\"\n",
    "    if not docs_or_text:\n",
    "        raise ValueError('docs_or_text cannot be empty')\n",
    "    if isinstance(docs_or_text, list):\n",
    "        text = \"\"\n",
    "        for doc in docs_or_text:\n",
    "            if not doc.page_content.strip() or len(doc.page_content.strip()) < 32:\n",
    "                continue\n",
    "            text = doc.page_content.strip()\n",
    "            break\n",
    "    else:\n",
    "        text = docs_or_text\n",
    "    text = \" \".join(text.split()[:max_words])\n",
    "    for i in range(retries+1):\n",
    "        obj = llm.pydantic_prompt(TITLE_PROMPT.replace(\"{context_str}\", text), pydantic_model=Title)\n",
    "        if not isinstance(obj, str):\n",
    "            break\n",
    "    return \"\" if isinstance(obj, str) else obj.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from onprem.utils import CAPTION_STR\n",
    "\n",
    "TABLE_PROMPT_EXACT= \"\"\"\\\n",
    "{context_str}\\n\\nWhat is this table about? Give a very concise summary (imagine you are adding a new caption and summary for this table), \\\n",
    "and output the real/existing table title/caption if context provided.\"\"\"\n",
    "TABLE_PROMPT= \"\"\"\\\n",
    "{context_str}\\n\\nWhat is this table about? Give a very concise summary (imagine you are adding a new caption and summary for this table).\"\"\"\n",
    "class TableSummary(BaseModel):\n",
    "    summary: str = Field(description=\"concise summary or caption of table\")\n",
    "\n",
    "def caption_table_text(table_text:str, llm, max_chars=4096, retries=1, attempt_exact=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Caption table text\n",
    "    \"\"\"\n",
    "    table_text = table_text[:max_chars]\n",
    "    for i in range(retries+1):\n",
    "        prompt = TABLE_PROMPT_EXACT if attempt_exact else TABLE_PROMPT\n",
    "        obj = llm.pydantic_prompt(prompt.replace(\"{context_str}\", table_text), pydantic_model=Title)\n",
    "        if not isinstance(obj, str):\n",
    "            break\n",
    "    return \"\" if isinstance(obj, str) else obj.title\n",
    "    \n",
    "def summarize_tables(docs:List[Document], llm, max_chars=4096, max_tables=3, retries=1, \n",
    "                   attempt_exact=False,\n",
    "                   only_caption_missing=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Given a list of Documents, auto-caption or summarize any tables within list.\n",
    "\n",
    "    **Args**\n",
    "      - docs_or_text: A list of LangChain Document objects\n",
    "      - llm: An onprem.LLM instance\n",
    "      - max_chars: Maximum characters to consider\n",
    "      - retries: Number of tries to correctly auto-caption table\n",
    "      - attempt_exact: Try to exact existing caption if it exists.\n",
    "      - only_caption_missing: Only caption tables without a caption\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        raise ValueError('docs_or_text cannot be empty')\n",
    "    n_processed = 0\n",
    "    for doc in docs:\n",
    "        if not 'table' in doc.metadata or not doc.metadata['table']:\n",
    "            continue\n",
    "        if only_caption_missing and CAPTION_STR in doc.page_content:\n",
    "            continue\n",
    "        doc.page_content = caption_table_text(doc.page_content, \n",
    "                                              llm=llm, max_chars=max_chars, retries=retries) + '\\n\\n' + doc.page_content        \n",
    "        n_processed +=1\n",
    "        if n_processed >= max_tables:\n",
    "            break\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "from onprem import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (3904) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "# |  notest\n",
    "\n",
    "llm = LLM(default_model='llama', n_gpu_layers=-1, verbose=False, mute_stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "from onprem.ingest import load_single_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Low-Code Library for Augmented Machine Learning\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "docs = load_single_document('tests/sample_data/ktrain_paper/ktrain_paper.pdf')\n",
    "title = extract_title(docs, llm=llm)\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-Caption Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "docs = load_single_document('tests/sample_data/ktrain_paper/ktrain_paper.pdf', infer_table_structure=True)\n",
    "table_doc = [d for d in docs if d.metadata['table']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "summarize_tables([table_doc], llm, only_caption_missing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of ML Tasks Supported in Popular Libraries\n",
      "\n",
      "Table 1: A comparison of ML tasks supported out-of-the-box in popular low-code and AutoML libraries for tabular, image, audio, text and graph data.\n",
      "\n",
      "The following table in markdown format has the caption: Table 1: A comparison of ML tasks supported out-of-the-box in popular low-code and AutoML libraries for tabular, image, audio, text and graph data. The following table in markdown format includes this list of columns:\n",
      "- Task\n",
      "- ktrain\n",
      "- fastai\n",
      "- Ludwig\n",
      "- AutoKeras\n",
      "- AutoGluon\n",
      "\n",
      "|Task|ktrain|fastai|Ludwig|AutoKeras|AutoGluon|\n",
      "|---|---|---|---|---|---|\n",
      "|Tabular: Classification/Regression|✓|✓|✓|✓|✓|\n",
      "|Tabular: Causal Machine Learning|✓|None|None|None|None|\n",
      "|Tabular: Time Series Forecasting|None|None|✓|✓|None|\n",
      "|Tabular: Collaborative Filtering|None|✓|None|None|None|\n",
      "|Image: Classification/Regression|✓|✓|✓|✓|✓|\n",
      "|Image: Object Detection|prefitted*|✓|None|None|✓|\n",
      "|Image: Image Captioning|prefitted*|None|✓|None|None|\n",
      "|Image: Segmentation|None|✓|None|None|None|\n",
      "|Image: GANs|None|✓|None|None|None|\n",
      "|Image: Keypoint/Pose Estimation|None|✓|None|None|None|\n",
      "|Audio: Classification/Regression|None|None|✓|None|None|\n",
      "|Audio: Speech Transcription|prefitted*|None|✓|None|None|\n",
      "|Text: Classification/Regression|✓|✓|✓|✓|✓|\n",
      "|Text: Sequence-Tagging|✓|None|✓|None|None|\n",
      "|Text: Unsupervised Topic Modeling|✓|None|None|None|None|\n",
      "|Text: Semantic Search|✓|None|None|None|None|\n",
      "|Text: End-to-End Question-Answering|✓*|None|None|None|None|\n",
      "|Text: Zero-Shot Learning|✓|None|None|None|None|\n",
      "|Text: Language Translation|prefitted*|None|✓|None|None|\n",
      "|Text: Summarization|prefitted*|None|✓|None|None|\n",
      "|Text: Text Extraction|✓|None|None|None|None|\n",
      "|Text: QA-Based Information Extraction|✓*|None|None|None|None|\n",
      "|Text: Keyphrase Extraction|✓|None|None|None|None|\n",
      "|Graph: Node Classification|✓|None|None|None|None|\n",
      "|Graph: Link Prediction|✓|None|None|None|None|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "print(table_doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `caption_tables` function pre-pended the table text with an alternative caption in this example.\n",
    "You can skip over tables that already have captions by supplying `only_caption_missing=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
