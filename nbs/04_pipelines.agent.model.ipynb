{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipelines.agent.model\n",
    "\n",
    "> Agent-friendly wrapper around and LLM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp pipelines.agent.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import re\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "from smolagents import ChatMessage, Model, get_clean_message_list, tool_role_conversions\n",
    "from smolagents.models import get_tool_call_from_text\n",
    "import onprem\n",
    "\n",
    "# Local implementation of remove_stop_sequences for compatibility with newer smolagents versions\n",
    "def remove_stop_sequences(text, stop_sequences):\n",
    "    \"\"\"Remove stop sequences from text\"\"\"\n",
    "    if not stop_sequences:\n",
    "        return text\n",
    "    \n",
    "    for stop_seq in stop_sequences:\n",
    "        if stop_seq in text:\n",
    "            # Remove the stop sequence and everything after it\n",
    "            text = text.split(stop_seq)[0]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class AgentModel(Model):\n",
    "    \"\"\"\n",
    "    A smolagents Model implementation that wraps an onprem LLM instance.\n",
    "    \n",
    "    This adapter allows onprem LLM instances to be used with smolagents Agents.\n",
    "    \n",
    "    Parameters:\n",
    "        llm (LLM): An instance of onprem.llm.base.LLM\n",
    "        **kwargs: Additional keyword arguments to pass to the parent Model class\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: onprem.LLM,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.llm = llm\n",
    "        self.maxlength=8192\n",
    "        self.model_id = self.llm.model_name\n",
    "        super().__init__(\n",
    "            flatten_messages_as_text=True,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def generate(\n",
    "        self,\n",
    "        messages,\n",
    "        stop_sequences=None,\n",
    "        response_format=None, \n",
    "        tools_to_call_from=None,\n",
    "        **kwargs\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Process the input messages and return the model's response.\n",
    "        \n",
    "        Parameters:\n",
    "            messages: A list of message dictionaries to be processed.\n",
    "            stop_sequences: A list of strings that will stop generation if encountered.\n",
    "            response_format: The response format to use in the model's response.\n",
    "            tools_to_call_from: A list of tools that the model can use.\n",
    "            **kwargs: Additional keyword arguments to pass to the LLM.\n",
    "            \n",
    "        Returns:\n",
    "            ChatMessage: A chat message object containing the model's response.\n",
    "        \"\"\"\n",
    "        # Convert smolagents messages to a format that onprem LLM can use\n",
    "        messages = self.clean(messages)\n",
    "        \n",
    "        # Call the LLM with the processed messages\n",
    "        #import litellm as api\n",
    "        #result = api.completion(\n",
    "                #model='ollama_chat/llama3.1:8b',\n",
    "                #messages=messages,\n",
    "                #max_tokens=self.maxlength,\n",
    "                #stream=False,\n",
    "                #stop=stop_sequences,\n",
    "            #)\n",
    "        #data = result[\"choices\"][0]\n",
    "        #text = data.get(\"text\", data.get(\"message\", data.get(\"delta\")))\n",
    "        #text = text if isinstance(text, str) else text.get(\"content\")\n",
    "        #response = text\n",
    "\n",
    "        response = self.llm.prompt(\n",
    "            messages,\n",
    "            stop=stop_sequences or [],\n",
    "            max_tokens = self.maxlength,\n",
    "            **kwargs\n",
    "        )\n",
    "        #print(f'RESPONSE: {response}')\n",
    "\n",
    "        # Remove stop sequences from LLM output\n",
    "        if stop_sequences is not None:\n",
    "            response = remove_stop_sequences(response, stop_sequences)\n",
    "        \n",
    "        # Create and return a ChatMessage with the response\n",
    "        message =  ChatMessage(role=\"assistant\", content=response)\n",
    "\n",
    "        # Extract first tool action\n",
    "        if tools_to_call_from:\n",
    "            # Try different patterns to extract JSON\n",
    "            extracted_json = None\n",
    "            \n",
    "            # Helper function to extract balanced JSON\n",
    "            def extract_balanced_json(text, start_pos):\n",
    "                brace_count = 0\n",
    "                in_string = False\n",
    "                escape_next = False\n",
    "                \n",
    "                for i, char in enumerate(text[start_pos:], start_pos):\n",
    "                    if escape_next:\n",
    "                        escape_next = False\n",
    "                        continue\n",
    "                    \n",
    "                    if char == '\\\\' and in_string:\n",
    "                        escape_next = True\n",
    "                        continue\n",
    "                    \n",
    "                    if char == '\"' and not escape_next:\n",
    "                        in_string = not in_string\n",
    "                        continue\n",
    "                    \n",
    "                    if not in_string:\n",
    "                        if char == '{':\n",
    "                            brace_count += 1\n",
    "                        elif char == '}':\n",
    "                            brace_count -= 1\n",
    "                            if brace_count == 0:\n",
    "                                return text[start_pos:i+1]\n",
    "                \n",
    "                return None\n",
    "            \n",
    "            # Pattern 1: Action: {...}\n",
    "            match = re.search(r\"Action:\\s*(\\{)\", response, flags=re.DOTALL)\n",
    "            if match:\n",
    "                start_pos = match.start(1)\n",
    "                extracted_json = extract_balanced_json(response, start_pos)\n",
    "            else:\n",
    "                # Pattern 2: Called Tool: 'name' with arguments: {...}\n",
    "                match = re.search(r\"Called Tool: '([^']+)' with arguments:\\s*(\\{)\", response, flags=re.DOTALL)\n",
    "                if match:\n",
    "                    tool_name = match.group(1)\n",
    "                    start_pos = match.start(2)\n",
    "                    args_json = extract_balanced_json(response, start_pos)\n",
    "                    if args_json:\n",
    "                        extracted_json = f'{{\"name\": \"{tool_name}\", \"arguments\": {args_json}}}'\n",
    "                else:\n",
    "                    # Pattern 3: Just the raw Called Tool format without proper JSON structure\n",
    "                    match = re.search(r\"Called Tool: '([^']+)' with arguments:\\s*(.+?)(?=\\n|$)\", response, flags=re.DOTALL)\n",
    "                    if match:\n",
    "                        tool_name, args_str = match.groups()\n",
    "                        # Try to fix the arguments format\n",
    "                        args_str = args_str.strip()\n",
    "                        if args_str.startswith('{') and args_str.endswith('}'):\n",
    "                            extracted_json = f'{{\"name\": \"{tool_name}\", \"arguments\": {args_str}}}'\n",
    "            \n",
    "            if extracted_json:\n",
    "                #print(f'EXTRACTED JSON: {repr(extracted_json)}')\n",
    "                # Fix JSON formatting: replace single quotes around keys/values but preserve apostrophes\n",
    "                import json\n",
    "                try:\n",
    "                    # Try to parse as-is first\n",
    "                    json.loads(extracted_json)\n",
    "                except json.JSONDecodeError:\n",
    "                    # Try a different approach - use ast.literal_eval style fixing\n",
    "                    import ast\n",
    "                    try:\n",
    "                        # Replace single quotes with double quotes more carefully\n",
    "                        # First fix obvious key patterns\n",
    "                        extracted_json = re.sub(r\"'(\\w+)':\", r'\"\\1\":', extracted_json)\n",
    "                        \n",
    "                        # Try to parse with Python's literal_eval which is more forgiving\n",
    "                        parsed = ast.literal_eval(extracted_json)\n",
    "                        # Convert back to JSON string\n",
    "                        import json\n",
    "                        extracted_json = json.dumps(parsed)\n",
    "                    except (ValueError, SyntaxError):\n",
    "                        # Fallback: manually escape problematic characters\n",
    "                        # Fix single quotes to double quotes for JSON structure\n",
    "                        lines = extracted_json.split('\\n')\n",
    "                        fixed_lines = []\n",
    "                        for line in lines:\n",
    "                            # Don't mess with the overall JSON structure\n",
    "                            if ':' in line and not line.strip().startswith('\"'):\n",
    "                                # This looks like a key-value pair, escape the value part\n",
    "                                key_part, value_part = line.split(':', 1)\n",
    "                                value_part = value_part.strip()\n",
    "                                # If it starts with a quote, escape internal quotes and newlines\n",
    "                                if value_part.startswith(\"'\") and value_part.endswith(\"'\"):\n",
    "                                    value_content = value_part[1:-1]  # Remove outer quotes\n",
    "                                    value_content = value_content.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"').replace('\\n', '\\\\n')\n",
    "                                    line = f'{key_part}: \"{value_content}\"'\n",
    "                                elif value_part.startswith('\"') and value_part.endswith('\"'):\n",
    "                                    value_content = value_part[1:-1]  # Remove outer quotes\n",
    "                                    value_content = value_content.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"').replace('\\n', '\\\\n')\n",
    "                                    line = f'{key_part}: \"{value_content}\"'\n",
    "                            fixed_lines.append(line)\n",
    "                        extracted_json = '\\n'.join(fixed_lines)\n",
    "                    #print(f'FIXED JSON: {repr(extracted_json)}')\n",
    "                \n",
    "                message.tool_calls = [\n",
    "                    get_tool_call_from_text(\n",
    "                        extracted_json, self.tool_name_key, self.tool_arguments_key\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "        return message\n",
    "\n",
    "\n",
    "    def parameters(self, maxlength):\n",
    "        \"\"\"\n",
    "        Set LLM inference parameters.\n",
    "\n",
    "        Args:\n",
    "            maxlength: maximum sequence length\n",
    "        \"\"\"\n",
    "\n",
    "        self.maxlength = maxlength\n",
    "\n",
    "\n",
    "    def clean(self, messages):\n",
    "        \"\"\"\n",
    "        Gets a clean message list.\n",
    "\n",
    "        Args:\n",
    "            messages: input messages\n",
    "\n",
    "        Returns:\n",
    "            clean messages\n",
    "        \"\"\"\n",
    "\n",
    "        # Get clean message list\n",
    "        messages = get_clean_message_list(messages, role_conversions=tool_role_conversions, flatten_messages_as_text=self.flatten_messages_as_text)\n",
    "\n",
    "        # Ensure all roles are strings and not enums for compability across LLM frameworks\n",
    "        for message in messages:\n",
    "            if \"role\" in message:\n",
    "                message[\"role\"] = message[\"role\"].value if isinstance(message[\"role\"], Enum) else message[\"role\"]\n",
    "\n",
    "        return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
