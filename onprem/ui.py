# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/99_ui.ipynb.

# %% auto 0
__all__ = []

# %% ../nbs/99_ui.ipynb 3
import streamlit as st
from langchain.callbacks import StreamlitCallbackHandler
from langchain.callbacks.base import BaseCallbackHandler
from langchain.callbacks.manager import CallbackManager
import os, yaml
from onprem import LLM, utils as U
DATADIR = U.get_datadir()
DEFAULT_PROMPT = "List three cute names for a cat."
def read_config():
    cfg_file = os.path.join(DATADIR, 'ui.yml')
    if not os.path.exists(cfg_file):
        raise ValueError(f'There is no ui.yml file in {DATADIR}. Please create one. An example ui.yml file is here: http://blah')
    with open(cfg_file, 'r') as stream:
        cfg = yaml.safe_load(stream)
    return cfg


@st.cache_resource
def get_llm():
    llm_config = read_config()['llm']
    return LLM(**llm_config)


# Page setup
cfg = read_config()
title = cfg['streamlit']['title']
st.set_page_config(page_title=title, page_icon="ðŸ", layout="wide")
st.title(title)

class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text="", display_method='markdown'):
        self.container = container
        self.text = initial_text
        self.display_method = display_method

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        with st.spinner('Typing...'):
            self.text += token + ""
            display_function = getattr(self.container, self.display_method, None)
            if display_function is not None:
                display_function(self.text)
            else:
                raise ValueError(f"Invalid display_method: {self.display_method}")


def setup_llm():
    llm = get_llm()
    chat_box = st.empty()
    stream_handler = StreamHandler(chat_box, display_method='write')
    _ = llm.load_llm()
    llm.llm.callbacks = [stream_handler]
    return llm

screen = st.sidebar.radio("Choose a Screen:",
                          ("Talk to Your Documents", "Use Prompts to Solve Problems"))
if screen == 'Talk to Your Documents':
    question = st.text_input("Enter a question and press the `Ask` button:", value="")
    ask_button = st.button("Ask")
    llm = setup_llm()

    if question and ask_button:
        question = question + ' '+cfg.get('prompt', {}).get('append_to_prompt', '')
        print(question)
        answer, docs = llm.ask(question)
        st.markdown('#### One or More of These Sources Were Used to Generate the Answer:')
        unique_sources = set()
        for doc in docs:
            unique_sources.add( (os.path.basename(doc.metadata['source']),
                                 doc.metadata.get('page', None), doc.page_content))
        unique_sources = list(unique_sources)
        for source in unique_sources:
            fname = source[0]
            page = source[1] +1 if isinstance(source[1], int) else source[1]
            content = source[2]
            st.markdown(f"- {fname} {', page '+str(page) if page else ''}", help=content)
else:
    prompt = st.text_area('Submit a Prompt to the LLM:', '', height=200, placeholder=DEFAULT_PROMPT)
    submit_button = st.button("Submit")
    llm = setup_llm()
    if prompt and submit_button:
        saved_output = llm.prompt(prompt)
