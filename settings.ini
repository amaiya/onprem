[DEFAULT]
# All sections below are required unless otherwise specified.
# See https://github.com/fastai/nbdev/blob/master/settings.ini for examples.

### Python library ###
repo = onprem
lib_name = %(repo)s
version = 0.19.2
min_python = 3.10
license = apache2
black_formatting = False

### nbdev ###
doc_path = _docs
lib_path = onprem
nbs_path = nbs
recursive = True
tst_flags = notest
put_version_in_init = True

### Docs ###
branch = master
custom_sidebar = True
doc_host = https://%(user)s.github.io
doc_baseurl = /%(repo)s
git_url = https://github.com/%(user)s/%(repo)s
title = %(lib_name)s

### PyPI ###
audience = Developers
author = Arun S. Maiya
author_email = arun@maiya.net
copyright = 2023 onwards, %(author)s
description = A tool for running on-premises large language models on non-public data
keywords = nbdev jupyter notebook python
language = English
status = 3
user = amaiya

### Optional ###
# Notes:
# pinning to ChromaDB due to backwards compatibility issues
# pinning nltk>=3.9.1 because unstructured fails on nltk==3.8.1
# pinning langchain_community>=0.3.18 because PyMUPDFLoader changed location of text_kwargs
# pinning: Setfit fails with datasets>4 due to https://github.com/huggingface/setfit/issues/608; REMOVE DATASETS FROM DEPS WHEN FIXED
# pinning: pymupdf4llm==0.0.17 because later versions produce lower-quality outputs based on tests
# pinning langchain_litellm==0.1.4 because 0.2.1 breaks when streaming=True
# optional: langchain_chroma, chromadb (required when supplying `store_type="dense"` to `LLM`)
# optional: elasticsearch              (required for ElasticsearchStore and ElasticsearchDualStore)
# optional: requests_ntlm              (required by SharePointStore)
# optional: shap                       (required by pipelines/classifier)
# optional: jieba                      (required by sk module)
# optional: boto3                      (required by ChatGovCloudBedrock)
# downloads: nltk punkt/averaged_perceptron_tagger (required by utils.extract_noun_phrases)
# downloads: models for infer_table_structure and ocr (required by load_single_document)
# agents: smolagents, markdownify and mcpadapt for agentic workflows
requirements = unstructured[all-docs] nltk>=3.9.1 PyMuPDF pymupdf4llm==0.0.17 extract-msg tabulate pandoc pypandoc requests tqdm syntok pandas sentence_transformers cmake setfit guidance>=0.1.5 langchain>=0.3.18 langchain-community>=0.3.18 langchain_litellm==0.1.4 litellm langchain-openai langchain-huggingface huggingface_hub transformers accelerate langdetect charset_normalizer python-magic whoosh-reloaded pyparsing openpyxl streamlit smolagents markdownify mcpadapt gmft datasets==3.6.0
dev_requirements = nbdev
chroma_requirements = chromadb langchain_chroma
explain_requirements = shap
console_scripts=onprem=onprem.app.console:cli
